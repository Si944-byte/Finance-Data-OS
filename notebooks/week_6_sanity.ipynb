{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68494a92-ebdf-4f29-8c19-ec0ec8561bf6",
   "metadata": {},
   "source": [
    "Create folders & a placeholder package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11b14e81-b0c8-4160-a702-4c538db38dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\fdos\\__init__.py\n",
      "exists: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\fdos\\paths.py\n",
      "exists: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\fdos\\config.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root = Path.cwd()  # you are in .../Finance Data OS/notebooks\n",
    "pkg_dir = root / \"src\" / \"fdos\"\n",
    "pkg_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# __init__.py\n",
    "init_py = pkg_dir / \"__init__.py\"\n",
    "if not init_py.exists():\n",
    "    init_py.write_text(\"\", encoding=\"utf-8\")\n",
    "    print(\"created:\", init_py)\n",
    "else:\n",
    "    print(\"exists:\", init_py)\n",
    "\n",
    "# paths.py (create only if missing)\n",
    "paths_py = pkg_dir / \"paths.py\"\n",
    "if not paths_py.exists():\n",
    "    paths_py.write_text(\n",
    "        \"\"\"from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "class LakeDiscoveryError(RuntimeError):\n",
    "    ...\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class LakePaths:\n",
    "    lake_root: Path\n",
    "\n",
    "def discover_lake(start: Path | None = None) -> Path:\n",
    "    \\\"\\\"\\\"Walk upward to find 'lake' that contains our parquet marts. Guard against ./notebooks/lake.\\\"\\\"\\\"\n",
    "    here = Path.cwd() if start is None else Path(start)\n",
    "    # guard: if a lake folder lives directly under notebooks, reject it\n",
    "    bad = here / \"lake\"\n",
    "    if bad.exists() and \"notebooks\" in str(here).lower():\n",
    "        raise LakeDiscoveryError(f\"Refusing to use {bad} â€” remove accidental 'notebooks/lake'.\")\n",
    "    for cand in [here, *here.parents]:\n",
    "        lk = cand / \"lake\"\n",
    "        if lk.exists():\n",
    "            return lk\n",
    "    raise LakeDiscoveryError(f\"Could not find a 'lake' folder walking up from {here}\")\n",
    "\n",
    "def feature_mart(lake_root: Path) -> Path:\n",
    "    return lake_root / \"feature_mart.parquet\"\n",
    "\n",
    "def signals_dir(lake_root: Path, output_version: str) -> Path:\n",
    "    return lake_root / f\"signals_mart_{output_version}.parquet\"\n",
    "\n",
    "def backtest_dir(lake_root: Path, output_version: str) -> Path:\n",
    "    return lake_root / f\"backtest_mart_{output_version}\"\n",
    "\n",
    "def summary_path(backtest_dir: Path) -> Path:\n",
    "    return backtest_dir / \"_summary.parquet\"\n",
    "\n",
    "def tuning_path(lake_root: Path) -> Path:\n",
    "    return lake_root / \"tuning_mart.parquet\"\n",
    "\"\"\",\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    print(\"created:\", paths_py)\n",
    "else:\n",
    "    print(\"exists:\", paths_py)\n",
    "\n",
    "# config.py (create only if missing)\n",
    "config_py = pkg_dir / \"config.py\"\n",
    "if not config_py.exists():\n",
    "    config_py.write_text(\n",
    "        r\"\"\"from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import hashlib, json, yaml  # type: ignore\n",
    "\n",
    "from .paths import discover_lake, feature_mart, signals_dir, backtest_dir, summary_path, tuning_path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    run_id: str\n",
    "    lake_root: Path\n",
    "    output_version: str\n",
    "    sma_fast: int\n",
    "    sma_slow: int\n",
    "    vol_window: int\n",
    "    vol_threshold_pct: float\n",
    "    costs_bps: int\n",
    "    tickers: list[str]\n",
    "    grids: dict\n",
    "\n",
    "    @property\n",
    "    def hash(self) -> str:\n",
    "        h = {\n",
    "            \"run_id\": self.run_id,\n",
    "            \"out\": self.output_version,\n",
    "            \"sma_fast\": self.sma_fast,\n",
    "            \"sma_slow\": self.sma_slow,\n",
    "            \"vol_window\": self.vol_window,\n",
    "            \"vol_threshold_pct\": self.vol_threshold_pct,\n",
    "            \"costs_bps\": self.costs_bps,\n",
    "            \"tickers\": self.tickers,\n",
    "        }\n",
    "        raw = json.dumps(h, sort_keys=True).encode()\n",
    "        return hashlib.md5(raw).hexdigest()[:8]\n",
    "\n",
    "def load_config(yaml_path: str | Path) -> Config:\n",
    "    ypath = Path(yaml_path)\n",
    "    data = yaml.safe_load(ypath.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    # fill lake_root: if yaml says \"\\\\lake\", resolve relative to repo\n",
    "    lake_root = Path(data.get(\"lake_root\", \"lake\"))\n",
    "    if str(lake_root) == r\"\\\\lake\":\n",
    "        # repo root is two levels up from src/fdos when imported\n",
    "        here = Path(__file__).resolve()\n",
    "        repo = here.parents[2]  # .../notebooks\n",
    "        lake_root = (repo / \"lake\").resolve()\n",
    "\n",
    "    return Config(\n",
    "        run_id=data[\"run_id\"],\n",
    "        lake_root=Path(lake_root).resolve(),\n",
    "        output_version=data.get(\"output_version\", \"v3\"),\n",
    "        sma_fast=int(data[\"sma_fast\"]),\n",
    "        sma_slow=int(data[\"sma_slow\"]),\n",
    "        vol_window=int(data[\"vol_window\"]),\n",
    "        vol_threshold_pct=float(data[\"vol_threshold_pct\"]),\n",
    "        costs_bps=int(data[\"costs_bps\"]),\n",
    "        tickers=list(map(str, data[\"tickers\"])),\n",
    "        grids=data.get(\"grids\", {}),\n",
    "    )\n",
    "\"\"\",\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    print(\"created:\", config_py)\n",
    "else:\n",
    "    print(\"exists:\", config_py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becfc4cf-ce5e-4b69-a58d-83c2e91663f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo root: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\n",
      "sys.path[0]: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\n",
      "RUN: week6-base HASH: a427440c\n",
      "LAKE (from config): C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\lake\n",
      "feature_mart: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\lake\\feature_mart.parquet\n",
      "signals_dir : C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\lake\\signals_mart_v3.parquet\n",
      "backtest_dir: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\lake\\backtest_mart_v3\n",
      "summary_path: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\lake\\backtest_mart_v3\\_summary.parquet\n",
      "tuning_path : C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\lake\\tuning_mart.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Find repo root by locating the package we just created\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    here = Path.cwd() if start is None else Path(start)\n",
    "    for cand in [here, *here.parents]:\n",
    "        if (cand / \"src\" / \"fdos\" / \"__init__.py\").exists():\n",
    "            return cand\n",
    "    raise RuntimeError(f\"Could not find repo root from {here} (looking for src/fdos/__init__.py)\")\n",
    "\n",
    "ROOT = find_repo_root()\n",
    "SRC = ROOT / \"src\"\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "print(\"repo root:\", ROOT)\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "# Now imports should work\n",
    "from fdos.config import load_config\n",
    "from fdos.paths import discover_lake, feature_mart, signals_dir, backtest_dir, summary_path, tuning_path\n",
    "\n",
    "cfg = load_config(ROOT / \"configs\" / \"base.yaml\")\n",
    "print(\"RUN:\", cfg.run_id, \"HASH:\", cfg.hash)\n",
    "print(\"LAKE (from config):\", cfg.lake_root)\n",
    "\n",
    "bt_dir = backtest_dir(cfg.lake_root, cfg.output_version)\n",
    "print(\"feature_mart:\", feature_mart(cfg.lake_root))\n",
    "print(\"signals_dir :\", signals_dir(cfg.lake_root, cfg.output_version))\n",
    "print(\"backtest_dir:\", bt_dir)\n",
    "print(\"summary_path:\", summary_path(bt_dir))\n",
    "print(\"tuning_path :\", tuning_path(cfg.lake_root))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f688a1b-8166-49fa-a56f-bc13e73f1f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discover: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\lake\n",
      "config: Config(run_id='week6-base', lake_root=WindowsPath('C:/Users/TJs PC/OneDrive/Desktop/Finance Data OS/lake'), output_version='v3', sma_fast=25, sma_slow=100, vol_window=20, vol_threshold_pct=20.0, costs_bps=5, tickers=['AAPL', 'MSFT', 'NVDA', 'TSLA'], grids={'fast': [10, 15, 20, 25, 30], 'slow': [50, 100, 150, 200], 'vol': [15.0, 20.0, 25.0]})\n"
     ]
    }
   ],
   "source": [
    "from fdos.paths import discover_lake\n",
    "print(\"discover:\", discover_lake())\n",
    "\n",
    "from fdos.config import load_config\n",
    "from pathlib import Path\n",
    "print(\"config:\", load_config(Path.cwd() / \"configs\" / \"base.yaml\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20553c19-39b6-4434-a2d9-85059ec59c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Schema DataFrameSchema(\n",
      "    columns={\n",
      "        'date': <Schema Column(name=date, type=DataType(datetime64[ns]))>\n",
      "        'ticker': <Schema Column(name=ticker, type=DataType(str))>\n",
      "        'sma_fast': <Schema Column(name=sma_fast, type=DataType(float64))>\n",
      "        'sma_slow': <Schema Column(name=sma_slow, type=DataType(float64))>\n",
      "        'long_rule': <Schema Column(name=long_rule, type=DataType(int64))>\n",
      "        'exit_rule': <Schema Column(name=exit_rule, type=DataType(int64))>\n",
      "        'high_vol': <Schema Column(name=high_vol, type=DataType(bool))>\n",
      "    },\n",
      "    checks=[],\n",
      "    parsers=[],\n",
      "    coerce=False,\n",
      "    dtype=None,\n",
      "    index=None,\n",
      "    strict=False,\n",
      "    name=None,\n",
      "    ordered=False,\n",
      "    unique_column_names=False,\n",
      "    metadata=None, \n",
      "    add_missing_columns=False\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "import importlib, fdos.validate as v\n",
    "importlib.reload(v)\n",
    "print(v.SCHEMAS[\"signals_mart_v3\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c2937ca-69e9-4282-824d-b19a990af268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] feature_mart_v3 schema passed\n"
     ]
    },
    {
     "ename": "SchemaError",
     "evalue": "expected series 'long_rule' to have type int64, got int32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSchemaError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     26\u001b[39m     sig = v.normalize_signals_columns(sig)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSCHEMAS\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msignals_mart_v3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquick_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[OK] signals_mart_v3 schema passed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\api\\pandas\\container.py:125\u001b[39m, in \u001b[36mDataFrameSchema.validate\u001b[39m\u001b[34m(self, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[39m\n\u001b[32m    113\u001b[39m     check_obj = check_obj.map_partitions(  \u001b[38;5;66;03m# type: ignore [operator]\u001b[39;00m\n\u001b[32m    114\u001b[39m         \u001b[38;5;28mself\u001b[39m._validate,\n\u001b[32m    115\u001b[39m         head=head,\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m         meta=check_obj,\n\u001b[32m    122\u001b[39m     )\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m check_obj.pandera.add_schema(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\api\\pandas\\container.py:154\u001b[39m, in \u001b[36mDataFrameSchema._validate\u001b[39m\u001b[34m(self, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_inferred:\n\u001b[32m    146\u001b[39m     warnings.warn(\n\u001b[32m    147\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is an inferred schema that hasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt been \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    148\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodified. It\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms recommended that you refine the schema \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    151\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    152\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\container.py:104\u001b[39m, in \u001b[36mDataFrameSchemaBackend.validate\u001b[39m\u001b[34m(self, check_obj, schema, head, tail, sample, random_state, lazy, inplace)\u001b[39m\n\u001b[32m     99\u001b[39m components = \u001b[38;5;28mself\u001b[39m.collect_schema_components(\n\u001b[32m    100\u001b[39m     check_obj, schema, column_info\n\u001b[32m    101\u001b[39m )\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# run the checks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m error_handler = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_checks_and_handle_errors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_handler.collected_errors:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[33m\"\u001b[39m\u001b[33mdrop_invalid_rows\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\container.py:179\u001b[39m, in \u001b[36mDataFrameSchemaBackend.run_checks_and_handle_errors\u001b[39m\u001b[34m(self, error_handler, schema, check_obj, column_info, sample, components, lazy, head, tail, random_state)\u001b[39m\n\u001b[32m    168\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    169\u001b[39m             error = SchemaError(\n\u001b[32m    170\u001b[39m                 schema,\n\u001b[32m    171\u001b[39m                 data=check_obj,\n\u001b[32m   (...)\u001b[39m\u001b[32m    177\u001b[39m                 reason_code=result.reason_code,\n\u001b[32m    178\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[43merror_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalidation_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreason_code\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreason_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m            \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43moriginal_exc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m error_handler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\api\\base\\error_handler.py:54\u001b[39m, in \u001b[36mErrorHandler.collect_error\u001b[39m\u001b[34m(self, error_type, reason_code, schema_error, original_exc)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Collect schema error, raising exception if lazy is False.\u001b[39;00m\n\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m \u001b[33;03m:param error_type: type of error\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m:param reason_code: string representing reason for error\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m:param schema_error: ``SchemaError`` object.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lazy:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m schema_error \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moriginal_exc\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# delete data of validated object from SchemaError object to prevent\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# storing copies of the validated DataFrame/Series for every\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# SchemaError collected.\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema_error, \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\container.py:200\u001b[39m, in \u001b[36mDataFrameSchemaBackend.run_schema_component_checks\u001b[39m\u001b[34m(self, check_obj, schema_components, lazy)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m schema_component \u001b[38;5;129;01min\u001b[39;00m schema_components:\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m         result = \u001b[43mschema_component\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m         check_passed.append(is_table(result))\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m SchemaError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\api\\dataframe\\components.py:163\u001b[39m, in \u001b[36mComponentSchema.validate\u001b[39m\u001b[34m(self, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate\u001b[39m(\n\u001b[32m    135\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    136\u001b[39m     check_obj,\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m ):\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# pylint: disable=too-many-locals,too-many-branches,too-many-statements\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate a series or specific column in dataframe.\u001b[39;00m\n\u001b[32m    146\u001b[39m \n\u001b[32m    147\u001b[39m \u001b[33;03m    :check_obj: data object to validate.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    161\u001b[39m \n\u001b[32m    162\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\components.py:132\u001b[39m, in \u001b[36mColumnBackend.validate\u001b[39m\u001b[34m(self, check_obj, schema, head, tail, sample, random_state, lazy, inplace)\u001b[39m\n\u001b[32m    128\u001b[39m             check_obj = validate_column(\n\u001b[32m    129\u001b[39m                 check_obj, column_name, return_check_obj=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    130\u001b[39m             )\n\u001b[32m    131\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m             \u001b[43mvalidate_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mand\u001b[39;00m error_handler.collected_errors:\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SchemaErrors(\n\u001b[32m    136\u001b[39m         schema=schema,\n\u001b[32m    137\u001b[39m         schema_errors=error_handler.schema_errors,\n\u001b[32m    138\u001b[39m         data=check_obj,\n\u001b[32m    139\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\components.py:92\u001b[39m, in \u001b[36mColumnBackend.validate.<locals>.validate_column\u001b[39m\u001b[34m(check_obj, column_name, return_check_obj)\u001b[39m\n\u001b[32m     88\u001b[39m         error_handler.collect_error(\n\u001b[32m     89\u001b[39m             validation_type(err.reason_code), err.reason_code, err\n\u001b[32m     90\u001b[39m         )\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SchemaError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[43merror_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreason_code\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreason_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\api\\base\\error_handler.py:54\u001b[39m, in \u001b[36mErrorHandler.collect_error\u001b[39m\u001b[34m(self, error_type, reason_code, schema_error, original_exc)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Collect schema error, raising exception if lazy is False.\u001b[39;00m\n\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m \u001b[33;03m:param error_type: type of error\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m:param reason_code: string representing reason for error\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m:param schema_error: ``SchemaError`` object.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lazy:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m schema_error \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moriginal_exc\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# delete data of validated object from SchemaError object to prevent\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# storing copies of the validated DataFrame/Series for every\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# SchemaError collected.\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema_error, \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\components.py:72\u001b[39m, in \u001b[36mColumnBackend.validate.<locals>.validate_column\u001b[39m\u001b[34m(check_obj, column_name, return_check_obj)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_column\u001b[39m(check_obj, column_name, return_check_obj=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     71\u001b[39m         \u001b[38;5;66;03m# pylint: disable=super-with-arguments\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m         validated_check_obj = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mColumnBackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43msample\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m            \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m return_check_obj:\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m validated_check_obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\array.py:81\u001b[39m, in \u001b[36mArraySchemaBackend.validate\u001b[39m\u001b[34m(self, check_obj, schema, head, tail, sample, random_state, lazy, inplace)\u001b[39m\n\u001b[32m     75\u001b[39m check_obj = \u001b[38;5;28mself\u001b[39m.run_parsers(\n\u001b[32m     76\u001b[39m     schema,\n\u001b[32m     77\u001b[39m     check_obj,\n\u001b[32m     78\u001b[39m )\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# run the core checks\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m error_handler = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_checks_and_handle_errors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mand\u001b[39;00m error_handler.collected_errors:\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[33m\"\u001b[39m\u001b[33mdrop_invalid_rows\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\array.py:145\u001b[39m, in \u001b[36mArraySchemaBackend.run_checks_and_handle_errors\u001b[39m\u001b[34m(self, error_handler, schema, check_obj, **subsample_kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    135\u001b[39m             error = SchemaError(\n\u001b[32m    136\u001b[39m                 schema=schema,\n\u001b[32m    137\u001b[39m                 data=check_obj,\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m                 reason_code=result.reason_code,\n\u001b[32m    144\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m             \u001b[43merror_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m                \u001b[49m\u001b[43mvalidation_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreason_code\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m                \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreason_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m                \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m                \u001b[49m\u001b[43moriginal_exc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43moriginal_exc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m error_handler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\api\\base\\error_handler.py:54\u001b[39m, in \u001b[36mErrorHandler.collect_error\u001b[39m\u001b[34m(self, error_type, reason_code, schema_error, original_exc)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Collect schema error, raising exception if lazy is False.\u001b[39;00m\n\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m \u001b[33;03m:param error_type: type of error\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m:param reason_code: string representing reason for error\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m:param schema_error: ``SchemaError`` object.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lazy:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m schema_error \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moriginal_exc\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# delete data of validated object from SchemaError object to prevent\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# storing copies of the validated DataFrame/Series for every\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# SchemaError collected.\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema_error, \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mSchemaError\u001b[39m: expected series 'long_rule' to have type int64, got int32"
     ]
    }
   ],
   "source": [
    "# 1) reload the module so your notebook sees the new code\n",
    "import importlib, fdos.validate as v\n",
    "importlib.reload(v)\n",
    "\n",
    "# 3) validate feature + signals (adjust the two paths to your machine if needed)\n",
    "from fdos.paths import discover_lake, feature_mart, signals_dir\n",
    "from fdos.io import read_parquet\n",
    "from fdos.config import load_config\n",
    "from pathlib import Path\n",
    "\n",
    "cfg = load_config(Path.cwd() / \"configs\" / \"base.yaml\")\n",
    "lake = discover_lake()\n",
    "\n",
    "fm_path  = feature_mart(lake)\n",
    "sig_path = signals_dir(lake, cfg.output_version).with_suffix(\".parquet\")\n",
    "\n",
    "fm  = read_parquet(fm_path)\n",
    "sig = read_parquet(sig_path) if sig_path.exists() else None\n",
    "\n",
    "# Validate feature mart\n",
    "v.SCHEMAS[\"feature_mart_v3\"].validate(v.quick_sample(fm))\n",
    "print(\"[OK] feature_mart_v3 schema passed\")\n",
    "\n",
    "# If you only have a v2 signals file, normalize first\n",
    "if sig is not None:\n",
    "    sig = v.normalize_signals_columns(sig)\n",
    "    v.SCHEMAS[\"signals_mart_v3\"].validate(v.quick_sample(sig))\n",
    "    print(\"[OK] signals_mart_v3 schema passed\")\n",
    "else:\n",
    "    print(\"[WARN] no signals file found yet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4da8bd-9b32-4952-9529-6f379af4e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature columns:\", sorted(fm.columns.tolist())[:20])\n",
    "print(\"Signals columns:\", sorted(sig.columns.tolist())[:20] if sig is not None else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "808977e9-101b-42cb-a932-63e88981442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sig head:\n",
      "        date ticker   return1  sma_fast  sma_slow  long_rule  exit_rule  \\\n",
      "0 2019-01-30   AAPL  0.068335       NaN       NaN          0          0   \n",
      "1 2019-01-31   AAPL  0.007202       NaN       NaN          0          0   \n",
      "2 2019-02-01   AAPL  0.000480       NaN       NaN          0          0   \n",
      "3 2019-02-04   AAPL  0.028405       NaN       NaN          0          0   \n",
      "4 2019-02-05   AAPL  0.017110       NaN       NaN          0          0   \n",
      "\n",
      "   high_vol  \n",
      "0     False  \n",
      "1     False  \n",
      "2     False  \n",
      "3     False  \n",
      "4     False  \n",
      "null counts:\n",
      " date           0\n",
      "ticker         0\n",
      "return1        0\n",
      "sma_fast      96\n",
      "sma_slow     396\n",
      "long_rule      0\n",
      "exit_rule      0\n",
      "high_vol       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "SchemaError",
     "evalue": "non-nullable series 'sma_fast' contains null values:\n23     NaN\n3100   NaN\n14     NaN\n17     NaN\n3103   NaN\n19     NaN\n3102   NaN\n3101   NaN\n1562   NaN\n1569   NaN\n4644   NaN\n3105   NaN\n15     NaN\n8      NaN\n1550   NaN\n1559   NaN\n1561   NaN\n3113   NaN\n1557   NaN\n1554   NaN\n4649   NaN\n1566   NaN\nName: sma_fast, dtype: float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSchemaError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnull counts:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, sig_norm.isna().sum())\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Validate a small sample (fast) â€” should PASS now\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mSCHEMAS\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msignals_mart_v3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig_norm\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msig_norm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Atomic write + manifest\u001b[39;00m\n\u001b[32m     43\u001b[39m write_parquet_safe(\n\u001b[32m     44\u001b[39m     df=sig_norm,\n\u001b[32m     45\u001b[39m     path=sig_path,\n\u001b[32m     46\u001b[39m     schema=SCHEMAS[\u001b[33m\"\u001b[39m\u001b[33msignals_mart_v3\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     47\u001b[39m     manifest={\u001b[33m\"\u001b[39m\u001b[33martifact\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msignals_mart_v3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mconfig_hash\u001b[39m\u001b[33m\"\u001b[39m: cfg.hash},\n\u001b[32m     48\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\api\\pandas\\container.py:125\u001b[39m, in \u001b[36mDataFrameSchema.validate\u001b[39m\u001b[34m(self, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[39m\n\u001b[32m    113\u001b[39m     check_obj = check_obj.map_partitions(  \u001b[38;5;66;03m# type: ignore [operator]\u001b[39;00m\n\u001b[32m    114\u001b[39m         \u001b[38;5;28mself\u001b[39m._validate,\n\u001b[32m    115\u001b[39m         head=head,\n\u001b[32m   (...)\u001b[39m\u001b[32m    121\u001b[39m         meta=check_obj,\n\u001b[32m    122\u001b[39m     )\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m check_obj.pandera.add_schema(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\api\\pandas\\container.py:154\u001b[39m, in \u001b[36mDataFrameSchema._validate\u001b[39m\u001b[34m(self, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_inferred:\n\u001b[32m    146\u001b[39m     warnings.warn(\n\u001b[32m    147\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is an inferred schema that hasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt been \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    148\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodified. It\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms recommended that you refine the schema \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    151\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    152\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\container.py:104\u001b[39m, in \u001b[36mDataFrameSchemaBackend.validate\u001b[39m\u001b[34m(self, check_obj, schema, head, tail, sample, random_state, lazy, inplace)\u001b[39m\n\u001b[32m     99\u001b[39m components = \u001b[38;5;28mself\u001b[39m.collect_schema_components(\n\u001b[32m    100\u001b[39m     check_obj, schema, column_info\n\u001b[32m    101\u001b[39m )\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# run the checks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m error_handler = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_checks_and_handle_errors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_handler.collected_errors:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[33m\"\u001b[39m\u001b[33mdrop_invalid_rows\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\container.py:179\u001b[39m, in \u001b[36mDataFrameSchemaBackend.run_checks_and_handle_errors\u001b[39m\u001b[34m(self, error_handler, schema, check_obj, column_info, sample, components, lazy, head, tail, random_state)\u001b[39m\n\u001b[32m    168\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    169\u001b[39m             error = SchemaError(\n\u001b[32m    170\u001b[39m                 schema,\n\u001b[32m    171\u001b[39m                 data=check_obj,\n\u001b[32m   (...)\u001b[39m\u001b[32m    177\u001b[39m                 reason_code=result.reason_code,\n\u001b[32m    178\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[43merror_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalidation_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreason_code\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreason_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m            \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43moriginal_exc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m error_handler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\api\\base\\error_handler.py:54\u001b[39m, in \u001b[36mErrorHandler.collect_error\u001b[39m\u001b[34m(self, error_type, reason_code, schema_error, original_exc)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Collect schema error, raising exception if lazy is False.\u001b[39;00m\n\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m \u001b[33;03m:param error_type: type of error\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m:param reason_code: string representing reason for error\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m:param schema_error: ``SchemaError`` object.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lazy:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m schema_error \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moriginal_exc\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# delete data of validated object from SchemaError object to prevent\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# storing copies of the validated DataFrame/Series for every\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# SchemaError collected.\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema_error, \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\container.py:200\u001b[39m, in \u001b[36mDataFrameSchemaBackend.run_schema_component_checks\u001b[39m\u001b[34m(self, check_obj, schema_components, lazy)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m schema_component \u001b[38;5;129;01min\u001b[39;00m schema_components:\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m         result = \u001b[43mschema_component\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m         check_passed.append(is_table(result))\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m SchemaError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\api\\dataframe\\components.py:163\u001b[39m, in \u001b[36mComponentSchema.validate\u001b[39m\u001b[34m(self, check_obj, head, tail, sample, random_state, lazy, inplace)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate\u001b[39m(\n\u001b[32m    135\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    136\u001b[39m     check_obj,\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m ):\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# pylint: disable=too-many-locals,too-many-branches,too-many-statements\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate a series or specific column in dataframe.\u001b[39;00m\n\u001b[32m    146\u001b[39m \n\u001b[32m    147\u001b[39m \u001b[33;03m    :check_obj: data object to validate.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    161\u001b[39m \n\u001b[32m    162\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\components.py:132\u001b[39m, in \u001b[36mColumnBackend.validate\u001b[39m\u001b[34m(self, check_obj, schema, head, tail, sample, random_state, lazy, inplace)\u001b[39m\n\u001b[32m    128\u001b[39m             check_obj = validate_column(\n\u001b[32m    129\u001b[39m                 check_obj, column_name, return_check_obj=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    130\u001b[39m             )\n\u001b[32m    131\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m             \u001b[43mvalidate_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mand\u001b[39;00m error_handler.collected_errors:\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SchemaErrors(\n\u001b[32m    136\u001b[39m         schema=schema,\n\u001b[32m    137\u001b[39m         schema_errors=error_handler.schema_errors,\n\u001b[32m    138\u001b[39m         data=check_obj,\n\u001b[32m    139\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\components.py:92\u001b[39m, in \u001b[36mColumnBackend.validate.<locals>.validate_column\u001b[39m\u001b[34m(check_obj, column_name, return_check_obj)\u001b[39m\n\u001b[32m     88\u001b[39m         error_handler.collect_error(\n\u001b[32m     89\u001b[39m             validation_type(err.reason_code), err.reason_code, err\n\u001b[32m     90\u001b[39m         )\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SchemaError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[43merror_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreason_code\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreason_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\api\\base\\error_handler.py:54\u001b[39m, in \u001b[36mErrorHandler.collect_error\u001b[39m\u001b[34m(self, error_type, reason_code, schema_error, original_exc)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Collect schema error, raising exception if lazy is False.\u001b[39;00m\n\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m \u001b[33;03m:param error_type: type of error\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m:param reason_code: string representing reason for error\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m:param schema_error: ``SchemaError`` object.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lazy:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m schema_error \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moriginal_exc\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# delete data of validated object from SchemaError object to prevent\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# storing copies of the validated DataFrame/Series for every\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# SchemaError collected.\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema_error, \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\components.py:72\u001b[39m, in \u001b[36mColumnBackend.validate.<locals>.validate_column\u001b[39m\u001b[34m(check_obj, column_name, return_check_obj)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_column\u001b[39m(check_obj, column_name, return_check_obj=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     71\u001b[39m         \u001b[38;5;66;03m# pylint: disable=super-with-arguments\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m         validated_check_obj = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mColumnBackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43msample\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m            \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m return_check_obj:\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m validated_check_obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\array.py:81\u001b[39m, in \u001b[36mArraySchemaBackend.validate\u001b[39m\u001b[34m(self, check_obj, schema, head, tail, sample, random_state, lazy, inplace)\u001b[39m\n\u001b[32m     75\u001b[39m check_obj = \u001b[38;5;28mself\u001b[39m.run_parsers(\n\u001b[32m     76\u001b[39m     schema,\n\u001b[32m     77\u001b[39m     check_obj,\n\u001b[32m     78\u001b[39m )\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# run the core checks\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m error_handler = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_checks_and_handle_errors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtail\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mand\u001b[39;00m error_handler.collected_errors:\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[33m\"\u001b[39m\u001b[33mdrop_invalid_rows\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\backends\\pandas\\array.py:145\u001b[39m, in \u001b[36mArraySchemaBackend.run_checks_and_handle_errors\u001b[39m\u001b[34m(self, error_handler, schema, check_obj, **subsample_kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    135\u001b[39m             error = SchemaError(\n\u001b[32m    136\u001b[39m                 schema=schema,\n\u001b[32m    137\u001b[39m                 data=check_obj,\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m                 reason_code=result.reason_code,\n\u001b[32m    144\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m             \u001b[43merror_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m                \u001b[49m\u001b[43mvalidation_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreason_code\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m                \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreason_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m                \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m                \u001b[49m\u001b[43moriginal_exc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43moriginal_exc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m error_handler\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\pandera\\api\\base\\error_handler.py:54\u001b[39m, in \u001b[36mErrorHandler.collect_error\u001b[39m\u001b[34m(self, error_type, reason_code, schema_error, original_exc)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Collect schema error, raising exception if lazy is False.\u001b[39;00m\n\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m \u001b[33;03m:param error_type: type of error\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m:param reason_code: string representing reason for error\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m:param schema_error: ``SchemaError`` object.\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lazy:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m schema_error \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moriginal_exc\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# delete data of validated object from SchemaError object to prevent\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# storing copies of the validated DataFrame/Series for every\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# SchemaError collected.\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema_error, \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mSchemaError\u001b[39m: non-nullable series 'sma_fast' contains null values:\n23     NaN\n3100   NaN\n14     NaN\n17     NaN\n3103   NaN\n19     NaN\n3102   NaN\n3101   NaN\n1562   NaN\n1569   NaN\n4644   NaN\n3105   NaN\n15     NaN\n8      NaN\n1550   NaN\n1559   NaN\n1561   NaN\n3113   NaN\n1557   NaN\n1554   NaN\n4649   NaN\n1566   NaN\nName: sma_fast, dtype: float64"
     ]
    }
   ],
   "source": [
    "# JUPYTER CELL â€” reload & rebuild signals v3\n",
    "import importlib\n",
    "import pandas as pd\n",
    "\n",
    "from fdos.config import load_config\n",
    "from fdos.paths import discover_lake, feature_mart, signals_dir\n",
    "import fdos.signals as s\n",
    "importlib.reload(s)            # <- pick up your file edits\n",
    "from fdos.signals import build_signals_v2\n",
    "\n",
    "from fdos.validate import SCHEMAS, normalize_signals_columns\n",
    "from fdos.io import write_parquet_safe\n",
    "from pathlib import Path\n",
    "\n",
    "cfg = load_config(Path.cwd() / \"configs\" / \"base.yaml\")\n",
    "lake = discover_lake()\n",
    "\n",
    "fm_path  = feature_mart(lake)\n",
    "sig_path = signals_dir(lake, cfg.output_version).with_suffix(\".parquet\")\n",
    "\n",
    "fm = pd.read_parquet(fm_path)\n",
    "\n",
    "sig = build_signals_v2(\n",
    "    fm,\n",
    "    sma_fast=cfg.sma_fast,\n",
    "    sma_slow=cfg.sma_slow,\n",
    "    vol_window=cfg.vol_window,\n",
    "    vol_threshold_pct=cfg.vol_threshold_pct,\n",
    ")\n",
    "\n",
    "# Optional normalization (ensures dtypes/bool/int exactly match schema)\n",
    "sig_norm = normalize_signals_columns(sig)\n",
    "\n",
    "# Sanity prints before writing\n",
    "print(\"sig head:\")\n",
    "print(sig_norm.head(5))\n",
    "print(\"null counts:\\n\", sig_norm.isna().sum())\n",
    "\n",
    "# Validate a small sample (fast) â€” should PASS now\n",
    "SCHEMAS[\"signals_mart_v3\"].validate(sig_norm.sample(min(1000, len(sig_norm)), random_state=42))\n",
    "\n",
    "# Atomic write + manifest\n",
    "write_parquet_safe(\n",
    "    df=sig_norm,\n",
    "    path=sig_path,\n",
    "    schema=SCHEMAS[\"signals_mart_v3\"],\n",
    "    manifest={\"artifact\": \"signals_mart_v3\", \"config_hash\": cfg.hash},\n",
    ")\n",
    "\n",
    "print(\"[OK] signals_mart_v3 written ->\", sig_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984406ce-ddf8-49de-9449-9cc6e777593f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signals.py at: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\fdos\\signals.py\n",
      "validate.py at: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\fdos\\validate.py\n",
      "Using schema object: <Schema DataFrameSchema(\n",
      "    columns={\n",
      "        'date': <Schema Column(name=date, type=DataType(datetime64[ns]))>\n",
      "        'ticker': <Schema Column(name=ticker, type=DataType(str))>\n",
      "        'sma_fast': <Schema Column(name=sma_fast, type=DataType(float64))>\n",
      "        'sma_slow': <Schema Column(name=sma_slow, type=DataType(float64))>\n",
      "        'long_rule': <Schema Column(name=long_rule, type=DataType(int64))>\n",
      "        'exit_rule': <Schema Column(name=exit_rule, type=DataType(int64))>\n",
      "        'high_vol': <Schema Column(name=high_vol, type=DataType(bool))>\n",
      "    },\n",
      "    checks=[],\n",
      "    parsers=[],\n",
      "    coerce=False,\n",
      "    dtype=None,\n",
      "    index=None,\n",
      "    strict=False,\n",
      "    name=None,\n",
      "    ordered=False,\n",
      "    unique_column_names=False,\n",
      "    metadata=None, \n",
      "    add_missing_columns=False\n",
      ")>\n",
      "sig head:\n",
      "         date ticker   return1  sma_fast  sma_slow  long_rule  exit_rule  \\\n",
      "0 2019-01-30   AAPL  0.068335       NaN       NaN          0          0   \n",
      "1 2019-01-31   AAPL  0.007202       NaN       NaN          0          0   \n",
      "2 2019-02-01   AAPL  0.000480       NaN       NaN          0          0   \n",
      "3 2019-02-04   AAPL  0.028405       NaN       NaN          0          0   \n",
      "4 2019-02-05   AAPL  0.017110       NaN       NaN          0          0   \n",
      "\n",
      "   high_vol  \n",
      "0     False  \n",
      "1     False  \n",
      "2     False  \n",
      "3     False  \n",
      "4     False  \n",
      "Parent exists? True  | Will write to: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\lake\\signals_mart_v3.parquet\n"
     ]
    }
   ],
   "source": [
    "import inspect, fdos.signals as s\n",
    "print(\"signals.py at:\", inspect.getsourcefile(s))\n",
    "print(\"validate.py at:\", inspect.getsourcefile(v))\n",
    "\n",
    "print(\"Using schema object:\", v.SCHEMAS[\"signals_mart_v3\"])\n",
    "print(\"sig head:\\n\", sig_norm.head())\n",
    "\n",
    "from pathlib import Path\n",
    "p = Path(sig_path)\n",
    "print(\"Parent exists?\", p.parent.exists(), \" | Will write to:\", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2daa602-b3eb-4af2-bf67-ac32ff40ec15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists? True -> C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\lake\\signals_mart_v3.parquet\n",
      "        date ticker   return1   sma_fast   sma_slow  long_rule  exit_rule  \\\n",
      "0 2019-06-21   AAPL -0.003409  44.875113  44.797405          1          0   \n",
      "1 2019-06-24   AAPL -0.001006  44.967035  44.880564          1          0   \n",
      "2 2019-06-25   AAPL -0.015158  45.086783  44.953671          1          0   \n",
      "3 2019-06-26   AAPL  0.021629  45.213439  45.036734          1          0   \n",
      "4 2019-06-27   AAPL -0.000300  45.376173  45.108399          1          0   \n",
      "\n",
      "   high_vol  \n",
      "0     False  \n",
      "1     False  \n",
      "2     False  \n",
      "3     False  \n",
      "4     False  \n",
      "NaNs: {'date': 0, 'ticker': 0, 'return1': 0, 'sma_fast': 0, 'sma_slow': 0, 'long_rule': 0, 'exit_rule': 0, 'high_vol': 0}\n",
      "[OK] full schema validate passed\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from fdos.paths import discover_lake, signals_dir\n",
    "from fdos.validate import SCHEMAS\n",
    "import pandas as pd\n",
    "from fdos.config import load_config\n",
    "\n",
    "cfg = load_config(Path.cwd() / \"configs\" / \"base.yaml\")\n",
    "lake = discover_lake()\n",
    "sig_path = signals_dir(lake, cfg.output_version).with_suffix(\".parquet\")\n",
    "print(\"Exists?\", Path(sig_path).exists(), \"->\", sig_path)\n",
    "\n",
    "sig = pd.read_parquet(sig_path)\n",
    "print(sig.head())\n",
    "print(\"NaNs:\", sig.isna().sum().to_dict())\n",
    "\n",
    "# full validate (can be slower)\n",
    "SCHEMAS[\"signals_mart_v3\"].validate(sig)\n",
    "print(\"[OK] full schema validate passed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea08290d-522e-4d45-b89e-da4931e05ae0",
   "metadata": {},
   "source": [
    "Cell A â€” imports + config/paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7859156f-590d-4864-8a10-5c6d1c134f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals file : C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\lake\\signals_mart_v3.parquet\n",
      "Backtest dir : C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\lake\\backtest_mart_v3\n",
      "Summary file : C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\lake\\backtest_mart_v3\\_summary.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from fdos.config import load_config\n",
    "from fdos.paths import discover_lake, signals_dir, backtest_dir, summary_path\n",
    "from fdos.backtest import run_backtest_with_costs, kpi\n",
    "from fdos.validate import SCHEMAS\n",
    "from fdos.io import read_parquet, write_parquet_safe\n",
    "\n",
    "cfg = load_config(Path.cwd() / \"configs\" / \"base.yaml\")\n",
    "lake = discover_lake()\n",
    "\n",
    "sig_path = signals_dir(lake, cfg.output_version).with_suffix(\".parquet\")\n",
    "bt_dir   = backtest_dir(lake, cfg.output_version)\n",
    "sum_path = summary_path(bt_dir)\n",
    "\n",
    "print(\"Signals file :\", sig_path)\n",
    "print(\"Backtest dir :\", bt_dir)\n",
    "print(\"Summary file :\", sum_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92b47d15-fd31-418d-9ab3-bbb960cec445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fdos.validate' from 'C:\\\\Users\\\\TJs PC\\\\OneDrive\\\\Desktop\\\\Finance Data OS\\\\notebooks\\\\src\\\\fdos\\\\validate.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, fdos.validate as v\n",
    "importlib.reload(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "987a9f0f-9866-448e-994b-3f4852b73f34",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "trades_from_position: missing columns: {'exit_rule', 'long_rule'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m btdir = backtest_dir(lake, cfg.output_version)\n\u001b[32m     12\u001b[39m daily  = read_parquet(btdir / \u001b[33m\"\u001b[39m\u001b[33m_daily.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m trades = \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrades_from_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdaily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcosts_bps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m trades_path = Path(lake) / \u001b[33m\"\u001b[39m\u001b[33mtrades_mart.parquet\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# NOTE: use the new key name here\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\fdos\\trades.py:13\u001b[39m, in \u001b[36mtrades_from_position\u001b[39m\u001b[34m(daily, cost_bps)\u001b[39m\n\u001b[32m     11\u001b[39m missing = must_have - \u001b[38;5;28mset\u001b[39m(daily.columns)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtrades_from_position: missing columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m df = daily.sort_values([\u001b[33m\"\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m]).copy()\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Derive position if it's not provided\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: trades_from_position: missing columns: {'exit_rule', 'long_rule'}"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from fdos.config import load_config\n",
    "from fdos.paths import discover_lake, backtest_dir\n",
    "from fdos.io import read_parquet, write_parquet_safe\n",
    "import fdos.trades as t\n",
    "import importlib; importlib.reload(t)  # in case you just edited trades.py\n",
    "\n",
    "cfg   = load_config(Path.cwd() / \"configs\" / \"base.yaml\")\n",
    "lake  = discover_lake()\n",
    "btdir = backtest_dir(lake, cfg.output_version)\n",
    "\n",
    "daily  = read_parquet(btdir / \"_daily.parquet\")\n",
    "trades = t.trades_from_position(daily, cfg.costs_bps)\n",
    "\n",
    "trades_path = Path(lake) / \"trades_mart.parquet\"\n",
    "\n",
    "# NOTE: use the new key name here\n",
    "v.SCHEMAS[\"trades_mart_v3\"].validate(trades.sample(min(1000, len(trades))))\n",
    "\n",
    "write_parquet_safe(\n",
    "    df=trades,\n",
    "    path=trades_path,\n",
    "    schema=v.SCHEMAS[\"trades_mart_v3\"],\n",
    "    manifest={\"artifact\": \"trades_mart\", \"config_hash\": cfg.hash},\n",
    ")\n",
    "\n",
    "print(\"[OK] trades mart written:\", trades_path)\n",
    "trades.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c0ebfa4-ead8-498c-b830-789320fdf772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tests_dir: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\notebooks\\src\\tests\n",
      "\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.02s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.NO_TESTS_COLLECTED: 5>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Reload the module so the notebook sees your fix\n",
    "import importlib, fdos.validate as v\n",
    "importlib.reload(v)\n",
    "\n",
    "# 2) Point pytest at the tests dir (relative to your notebook)\n",
    "from pathlib import Path\n",
    "import sys, pytest\n",
    "\n",
    "repo = Path.cwd()\n",
    "if not (repo / \"notebooks\").exists():\n",
    "    repo = repo.parent  # if you're inside notebooks/, this is a no-op\n",
    "\n",
    "tests_dir = repo / \"notebooks\" / \"src\" / \"tests\"\n",
    "if str(repo / \"notebooks\" / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(repo / \"notebooks\" / \"src\"))\n",
    "\n",
    "print(\"Using tests_dir:\", tests_dir)\n",
    "\n",
    "# 3) Run just one test first\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_sma_alignment\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99a7949c-4e05-4f67-a63a-387105b823d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\n",
      "TESTS_DIR: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\notebooks\\src\\tests\n",
      "SYS.PATH head: ['C:\\\\Users\\\\TJs PC\\\\OneDrive\\\\Desktop\\\\Finance Data OS\\\\notebooks\\\\notebooks\\\\src', 'C:\\\\Users\\\\TJs PC\\\\OneDrive\\\\Desktop\\\\Finance Data OS\\\\notebooks\\\\src']\n",
      "\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.04s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.NO_TESTS_COLLECTED: 5>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys, pytest\n",
    "\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    \"\"\"Walk upward until we find a folder that contains notebooks/src/tests.\"\"\"\n",
    "    here = Path.cwd() if start is None else Path(start)\n",
    "    for cand in (here, *here.parents):\n",
    "        if (cand / \"notebooks\" / \"src\" / \"tests\").exists():\n",
    "            return cand\n",
    "    raise FileNotFoundError(f\"Could not find 'notebooks/src/tests' walking up from {here}\")\n",
    "\n",
    "# 1) Locate repo root and tests dir once â€“ no more double 'notebooks'\n",
    "ROOT = find_repo_root()\n",
    "TESTS_DIR = ROOT / \"notebooks\" / \"src\" / \"tests\"\n",
    "SRC_DIR = ROOT / \"notebooks\" / \"src\"\n",
    "\n",
    "# 2) Ensure imports work for fdos/*\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"TESTS_DIR:\", TESTS_DIR)\n",
    "print(\"SYS.PATH head:\", sys.path[:2])\n",
    "\n",
    "# 3) (Optional) hot-reload validate after your edit so tests see the fix\n",
    "import importlib, fdos.validate as v\n",
    "importlib.reload(v)\n",
    "\n",
    "# 4) Run one test first (fastest feedback)\n",
    "pytest.main([\"-q\", str(TESTS_DIR), \"-k\", \"test_sma_alignment\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "968d845a-10e7-449a-89fd-2585bff5049e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fdos.signals' from 'C:\\\\Users\\\\TJs PC\\\\OneDrive\\\\Desktop\\\\Finance Data OS\\\\notebooks\\\\src\\\\fdos\\\\signals.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, fdos.signals as s\n",
    "importlib.reload(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faa5aaed-f83b-475c-b33d-f8bc5e50dd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.07s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.NO_TESTS_COLLECTED: 5>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytest\n",
    "pytest.main([\"-q\", str(TESTS_DIR), \"-k\", \"test_sma_alignment\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73a9b155-c264-4f67-8558-127873232828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>return1</th>\n",
       "      <th>sma_fast</th>\n",
       "      <th>sma_slow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.003409</td>\n",
       "      <td>44.875113</td>\n",
       "      <td>44.797405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-06-24</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.001006</td>\n",
       "      <td>44.967035</td>\n",
       "      <td>44.880564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.015158</td>\n",
       "      <td>45.086783</td>\n",
       "      <td>44.953671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-06-26</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.021629</td>\n",
       "      <td>45.213439</td>\n",
       "      <td>45.036734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>45.376173</td>\n",
       "      <td>45.108399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2019-11-07</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.011541</td>\n",
       "      <td>58.127937</td>\n",
       "      <td>52.114928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2019-11-08</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>58.454554</td>\n",
       "      <td>52.268552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.007919</td>\n",
       "      <td>58.800591</td>\n",
       "      <td>52.423337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>59.169929</td>\n",
       "      <td>52.579174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2019-11-13</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>59.538185</td>\n",
       "      <td>52.741553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date ticker   return1   sma_fast   sma_slow\n",
       "0   2019-06-21   AAPL -0.003409  44.875113  44.797405\n",
       "1   2019-06-24   AAPL -0.001006  44.967035  44.880564\n",
       "2   2019-06-25   AAPL -0.015158  45.086783  44.953671\n",
       "3   2019-06-26   AAPL  0.021629  45.213439  45.036734\n",
       "4   2019-06-27   AAPL -0.000300  45.376173  45.108399\n",
       "..         ...    ...       ...        ...        ...\n",
       "97  2019-11-07   AAPL  0.011541  58.127937  52.114928\n",
       "98  2019-11-08   AAPL  0.002737  58.454554  52.268552\n",
       "99  2019-11-11   AAPL  0.007919  58.800591  52.423337\n",
       "100 2019-11-12   AAPL -0.000915  59.169929  52.579174\n",
       "101 2019-11-13   AAPL  0.009582  59.538185  52.741553\n",
       "\n",
       "[102 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = sig[sig[\"ticker\"] == sig[\"ticker\"].iloc[0]].head(max(60, cfg.sma_slow+5))\n",
    "one[[\"date\",\"ticker\",\"return1\",\"sma_fast\",\"sma_slow\"]].head(cfg.sma_slow+2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bde7bfb-c362-41de-b1f5-97c3d94579c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in first slow-window rows per ticker:\n",
      "sma_fast     96\n",
      "sma_slow    396\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from fdos.config import load_config\n",
    "from fdos.paths import feature_mart\n",
    "from fdos.signals import build_signals_v2\n",
    "from fdos.validate import normalize_signals_columns\n",
    "\n",
    "cfg = load_config(Path.cwd() / \"configs\" / \"base.yaml\")\n",
    "fm  = pd.read_parquet(feature_mart(cfg.lake_root))\n",
    "\n",
    "sig = build_signals_v2(\n",
    "    fm,\n",
    "    sma_fast=cfg.sma_fast,\n",
    "    sma_slow=cfg.sma_slow,\n",
    "    vol_window=cfg.vol_window,\n",
    "    vol_threshold_pct=cfg.vol_threshold_pct,\n",
    ")\n",
    "sig = normalize_signals_columns(sig)\n",
    "\n",
    "# NaNs expected in the leading rows per ticker:\n",
    "head_block = sig.groupby(\"ticker\").head(cfg.sma_slow)\n",
    "print(\"NaNs in first slow-window rows per ticker:\")\n",
    "print(head_block[[\"sma_fast\",\"sma_slow\"]].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d10f9e6f-c0c3-47a6-98af-504fc97995e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fdos.signals' from 'C:\\\\Users\\\\TJs PC\\\\OneDrive\\\\Desktop\\\\Finance Data OS\\\\notebooks\\\\src\\\\fdos\\\\signals.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, fdos.signals as s\n",
    "importlib.reload(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f045a633-1094-4501-98bb-d8185deecd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sma_fast     96\n",
      "sma_slow    396\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import importlib, fdos.signals as s\n",
    "importlib.reload(s)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from fdos.config import load_config\n",
    "from fdos.paths import feature_mart\n",
    "from fdos.validate import normalize_signals_columns\n",
    "\n",
    "cfg = load_config(Path.cwd() / \"configs\" / \"base.yaml\")\n",
    "fm = pd.read_parquet(feature_mart(cfg.lake_root))\n",
    "\n",
    "sig = s.build_signals_v2(\n",
    "    fm,\n",
    "    sma_fast=cfg.sma_fast,\n",
    "    sma_slow=cfg.sma_slow,\n",
    "    vol_window=cfg.vol_window,\n",
    "    vol_threshold_pct=cfg.vol_threshold_pct,\n",
    ")\n",
    "sig = normalize_signals_columns(sig)\n",
    "\n",
    "# quick sanity: first slow-window rows per ticker should have NaNs in SMAs\n",
    "head_block = sig.groupby(\"ticker\").head(cfg.sma_slow)\n",
    "print(head_block[[\"sma_fast\",\"sma_slow\"]].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c851c24-6e29-4ccc-b2b2-a352f52e66d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in first slow-window block across all columns: 492\n",
      "['date', 'ticker', 'return1', 'sma_fast', 'sma_slow', 'long_rule', 'exit_rule', 'high_vol']\n",
      "date         datetime64[ns]\n",
      "ticker               object\n",
      "return1             float64\n",
      "sma_fast            float64\n",
      "sma_slow            float64\n",
      "long_rule             int32\n",
      "exit_rule             int32\n",
      "high_vol               bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 1) Force-reload your module that defines build_signals_v2\n",
    "import importlib, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import fdos.signals as s\n",
    "importlib.reload(s)\n",
    "\n",
    "from fdos.config import load_config\n",
    "from fdos.paths import feature_mart\n",
    "from fdos.validate import normalize_signals_columns\n",
    "\n",
    "cfg = load_config(Path.cwd() / \"configs\" / \"base.yaml\")\n",
    "fm  = pd.read_parquet(feature_mart(cfg.lake_root))\n",
    "\n",
    "sig = s.build_signals_v2(\n",
    "    fm,\n",
    "    sma_fast=cfg.sma_fast,\n",
    "    sma_slow=cfg.sma_slow,\n",
    "    vol_window=cfg.vol_window,\n",
    "    vol_threshold_pct=cfg.vol_threshold_pct,\n",
    ")\n",
    "sig = normalize_signals_columns(sig)\n",
    "\n",
    "head = sig.groupby(\"ticker\").head(cfg.sma_slow).isna().sum().sum()\n",
    "print(\"NaNs in first slow-window block across all columns:\", head)\n",
    "\n",
    "print(sig.columns.tolist())\n",
    "print(sig.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08e1b2c4-cbc1-470b-a284-672e4f346a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fdos.signals' from 'C:\\\\Users\\\\TJs PC\\\\OneDrive\\\\Desktop\\\\Finance Data OS\\\\notebooks\\\\src\\\\fdos\\\\signals.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, fdos.signals as s\n",
    "importlib.reload(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efef5501-7044-4188-bd1c-ee8b4a344b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[33m                                                                                                            [100%]\u001b[0m\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m4 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.07s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, fdos.signals as s\n",
    "importlib.reload(s)\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, pytest\n",
    "\n",
    "repo = Path.cwd() if Path.cwd().name == \"notebooks\" else Path.cwd() / \"notebooks\"\n",
    "tests_dir = repo / \"src\" / \"tests\"\n",
    "src_dir   = repo / \"src\"\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_sma_alignment\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1719147d-f45e-40e3-9f3f-08536496830e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[33m                                                                                                            [100%]\u001b[0m\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "src/tests/test_drawdown_roll.py::test_drawdown_and_rolling\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\fdos\\backtest.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "    d = d.groupby(\"ticker\", group_keys=False).apply(per_ticker)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m4 deselected\u001b[0m, \u001b[33m\u001b[1m2 warnings\u001b[0m\u001b[33m in 0.16s\u001b[0m\u001b[0m\n",
      "\u001b[31mF\u001b[0m\u001b[31m                                                                                                            [100%]\u001b[0m\n",
      "==================================================== FAILURES =====================================================\n",
      "\u001b[31m\u001b[1m___________________________________________ test_cost_application_sign ____________________________________________\u001b[0m\n",
      "\n",
      "feature_df =            date ticker       close   return1       sma10      vol20\n",
      "0    2019-01-30   AAPL   39.319290  0.068335   37....290  338.982001   8.553405\n",
      "6183 2025-09-05   TSLA  350.839996  0.036363  342.055002   8.564378\n",
      "\n",
      "[6184 rows x 6 columns]\n",
      "cfg = Config(run_id='week6-base', lake_root=WindowsPath('C:/Users/TJs PC/OneDrive/Desktop/Finance Data OS/lake'), output_ver... 'MSFT', 'NVDA', 'TSLA'], grids={'fast': [10, 15, 20, 25, 30], 'slow': [50, 100, 150, 200], 'vol': [15.0, 20.0, 25.0]})\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_cost_application_sign\u001b[39;49;00m(feature_df, cfg):\u001b[90m\u001b[39;49;00m\n",
      "        sig = build_signals_v2(feature_df, cfg.sma_fast, cfg.sma_slow, cfg.vol_window, cfg.vol_threshold_pct)\u001b[90m\u001b[39;49;00m\n",
      "        sig = normalize_signals_columns(sig)\u001b[90m\u001b[39;49;00m\n",
      "        daily = run_backtest_with_costs(sig, cost_bps=cfg.costs_bps)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# cost reduces returns or equal (when no trades)\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m (daily[\u001b[33m\"\u001b[39;49;00m\u001b[33mret_after_cost\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] <= daily[\u001b[33m\"\u001b[39;49;00m\u001b[33mreturn1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] + \u001b[94m1e-12\u001b[39;49;00m).all()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where False = all()\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where all = 0       0.000000\\n1       0.000000\\n2       0.000000\\n3       0.000000\\n4       0.000000\\n          ...   \\n6179   -0.035002\\n6180   -0.013508\\n6181    0.014361\\n6182    0.013290\\n6183    0.036363\\nName: ret_after_cost, Length: 6184, dtype: float64 <= (0       0.068335\\n1       0.007202\\n2       0.000480\\n3       0.028405\\n4       0.017110\\n          ...   \\n6179   -0.035002\\n6180   -0.013508\\n6181    0.014361\\n6182    0.013290\\n6183    0.036363\\nName: return1, Length: 6184, dtype: float64 + 1e-12).all\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31msrc\\tests\\test_units.py\u001b[0m:22: AssertionError\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "src/tests/test_units.py::test_cost_application_sign\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\fdos\\backtest.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "    d = d.groupby(\"ticker\", group_keys=False).apply(per_ticker)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[36m\u001b[1m============================================= short test summary info =============================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m src/tests/test_units.py::\u001b[1mtest_cost_application_sign\u001b[0m - assert False\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m4 deselected\u001b[0m, \u001b[33m2 warnings\u001b[0m\u001b[31m in 0.29s\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[33m\u001b[1m5 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.03s\u001b[0m\u001b[0m\n",
      "\u001b[32m.\u001b[0m\u001b[33m                                                                                                            [100%]\u001b[0m\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m4 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.16s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drawdown/rolling\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_drawdown_roll\"])\n",
    "\n",
    "# cost-sign\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_cost_application_sign\"])\n",
    "\n",
    "# tiny end-to-end\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_e2e_small\"])\n",
    "\n",
    "# KPI parity (reads fixture parquet)\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_kpi_parity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1654d112-7f48-4bc1-8f96-5b4a8274f173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixture written to: notebooks\\src\\tests\\fixtures\\week5_summary.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from fdos.config import load_config\n",
    "from fdos.paths import discover_lake, backtest_dir, summary_path\n",
    "from fdos.io import read_parquet, write_parquet_safe\n",
    "\n",
    "# 1) Load your current summary (the one you already wrote earlier)\n",
    "cfg   = load_config(Path.cwd() / \"configs\" / \"base.yaml\")\n",
    "lake  = discover_lake()\n",
    "btdir = backtest_dir(lake, cfg.output_version)\n",
    "summary_df = read_parquet(summary_path(btdir))   # this is backtest_mart_v3/_summary.parquet\n",
    "\n",
    "# 2) Save it as the test fixture the parity test expects\n",
    "fixtures_dir = Path(\"notebooks/src/tests/fixtures\")\n",
    "fixtures_dir.mkdir(parents=True, exist_ok=True)\n",
    "fixture_path = fixtures_dir / \"week5_summary.parquet\"\n",
    "\n",
    "write_parquet_safe(\n",
    "    df=summary_df,\n",
    "    path=fixture_path,\n",
    "    manifest={\"artifact\": \"test_fixture\", \"source\": \"local summary_v3\"}\n",
    ")\n",
    "print(\"Fixture written to:\", fixture_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "294a282a-0204-470c-b876-33477b914e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.05s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.NO_TESTS_COLLECTED: 5>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytest, sys\n",
    "from pathlib import Path\n",
    "\n",
    "# point pytest at repo tests (same pattern you used before)\n",
    "repo = Path.cwd() / \"notebooks\" if Path.cwd().name == \"notebooks\" else Path.cwd() / \"notebooks\"\n",
    "tests_dir = repo / \"src\" / \"tests\"\n",
    "\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_kpi_parity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acd28323-c26e-44a3-8241-16d2f808313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.NO_TESTS_COLLECTED: 5>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_drawdown_roll or test_cost_application_sign or test_e2e_small or test_kpi_parity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b7f1cf4-b831-4add-8567-b9fd904f0c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[33m                                                                                                            [100%]\u001b[0m\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m4 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.05s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytest, sys\n",
    "from pathlib import Path\n",
    "\n",
    "# point to the repo's notebooks dir (no double \"notebooks\")\n",
    "repo = Path.cwd() if Path.cwd().name == \"notebooks\" else Path.cwd() / \"notebooks\"\n",
    "tests_dir = repo / \"src\" / \"tests\"\n",
    "src_dir   = repo / \"src\"\n",
    "\n",
    "# ensure src is importable (safe no-op if already there)\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# run just the KPI parity test\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_kpi_parity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "048d920a-df57-4643-adfb-84f4d0c634e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Fixture written to: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\tests\\fixtures\\week5_summary.parquet\n",
      "[OK] Extra copy written to: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\fdos\\week5_summary.parquet\n",
      "Exists? -> True True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# fdos helpers (already in your repo)\n",
    "from fdos.config import load_config\n",
    "from fdos.paths import discover_lake, backtest_dir, summary_path\n",
    "from fdos.io import read_parquet, write_parquet_safe\n",
    "\n",
    "# --- locate repo paths (handles running inside notebooks/ or repo root) ---\n",
    "repo_root = Path.cwd() if Path.cwd().name == \"notebooks\" else Path.cwd() / \"notebooks\"\n",
    "src_dir   = repo_root / \"src\"\n",
    "tests_dir = src_dir / \"tests\"\n",
    "fixtures_dir = tests_dir / \"fixtures\"\n",
    "\n",
    "# also drop a copy \"in the fdos folder\" as requested\n",
    "fdos_dir = src_dir / \"fdos\"\n",
    "\n",
    "# --- read your latest summary (the v3 summary you already wrote earlier) ---\n",
    "cfg   = load_config(Path.cwd() / \"configs\" / \"base.yaml\")\n",
    "lake  = discover_lake()\n",
    "btdir = backtest_dir(lake, cfg.output_version)\n",
    "summary_df = read_parquet(summary_path(btdir))  # this is notebooks/lake/backtest_mart_v3/_summary.parquet\n",
    "\n",
    "# --- ensure output folders exist ---\n",
    "fixtures_dir.mkdir(parents=True, exist_ok=True)\n",
    "fdos_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- write the two copies safely (with tiny manifest) ---\n",
    "fixture_path = fixtures_dir / \"week5_summary.parquet\"\n",
    "fdos_copy    = fdos_dir     / \"week5_summary.parquet\"\n",
    "\n",
    "manifest = {\"artifact\": \"test_fixture\", \"source\": \"local_summary_v3\"}\n",
    "\n",
    "write_parquet_safe(df=summary_df, path=fixture_path, manifest=manifest)\n",
    "write_parquet_safe(df=summary_df, path=fdos_copy,    manifest=manifest)\n",
    "\n",
    "print(\"[OK] Fixture written to:\", fixture_path)\n",
    "print(\"[OK] Extra copy written to:\", fdos_copy)\n",
    "print(\"Exists? ->\", fixture_path.exists(), fdos_copy.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac7e3884-c23d-46cf-8809-4d545b1d3c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[33m                                                                                                            [100%]\u001b[0m\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m4 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.09s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytest, sys\n",
    "from pathlib import Path\n",
    "\n",
    "repo = Path.cwd() if Path.cwd().name == \"notebooks\" else Path.cwd() / \"notebooks\"\n",
    "tests_dir = repo / \"src\" / \"tests\"\n",
    "src_dir   = repo / \"src\"\n",
    "\n",
    "# make sure src is importable\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_kpi_parity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bb193d7-4374-4fa4-be06-27c857305e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] wrote: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\tests\\fixtures\\week5_summary.parquet\n",
      "[OK] wrote: C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\fixtures\\week5_summary.parquet\n",
      "Exists? -> True True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from fdos.config import load_config\n",
    "from fdos.paths import discover_lake, backtest_dir, summary_path\n",
    "from fdos.io import read_parquet, write_parquet_safe\n",
    "\n",
    "# Locate repo (works whether you're in notebooks/ or repo root)\n",
    "repo = Path.cwd() if Path.cwd().name == \"notebooks\" else Path.cwd() / \"notebooks\"\n",
    "\n",
    "tests_fixtures = repo / \"src\" / \"tests\" / \"fixtures\" / \"week5_summary.parquet\"   # where you already wrote\n",
    "root_fixtures  = repo / \"fixtures\" / \"week5_summary.parquet\"                     # ALSO write here (fixes relative path)\n",
    "\n",
    "# Pull your current v3 summary\n",
    "cfg   = load_config(Path.cwd() / \"configs\" / \"base.yaml\")\n",
    "lake  = discover_lake()\n",
    "btdir = backtest_dir(lake, cfg.output_version)\n",
    "summary_df = read_parquet(summary_path(btdir))\n",
    "\n",
    "# Ensure dirs and write both copies\n",
    "tests_fixtures.parent.mkdir(parents=True, exist_ok=True)\n",
    "root_fixtures.parent.mkdir(parents=True, exist_ok=True)\n",
    "manifest = {\"artifact\": \"test_fixture\", \"source\": \"local_summary_v3\"}\n",
    "\n",
    "write_parquet_safe(df=summary_df, path=tests_fixtures, manifest=manifest)\n",
    "write_parquet_safe(df=summary_df, path=root_fixtures,  manifest=manifest)\n",
    "\n",
    "print(\"[OK] wrote:\", tests_fixtures)\n",
    "print(\"[OK] wrote:\", root_fixtures)\n",
    "print(\"Exists? ->\", tests_fixtures.exists(), root_fixtures.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50fc05fa-3e0a-44d3-b73a-088f7f16b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[33m                                                                                                            [100%]\u001b[0m\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m4 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.08s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytest, sys\n",
    "from pathlib import Path\n",
    "\n",
    "repo = Path.cwd() if Path.cwd().name == \"notebooks\" else Path.cwd() / \"notebooks\"\n",
    "tests_dir = repo / \"src\" / \"tests\"\n",
    "src_dir   = repo / \"src\"\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_kpi_parity\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14e4bad5-799d-45d1-8dbe-04f75c328338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[33m                                                                                                            [100%]\u001b[0m\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "src/tests/test_drawdown_roll.py::test_drawdown_and_rolling\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\fdos\\backtest.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "    d = d.groupby(\"ticker\", group_keys=False).apply(per_ticker)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m4 deselected\u001b[0m, \u001b[33m\u001b[1m2 warnings\u001b[0m\u001b[33m in 0.39s\u001b[0m\u001b[0m\n",
      "\u001b[31mF\u001b[0m\u001b[31m                                                                                                            [100%]\u001b[0m\n",
      "==================================================== FAILURES =====================================================\n",
      "\u001b[31m\u001b[1m___________________________________________ test_cost_application_sign ____________________________________________\u001b[0m\n",
      "\n",
      "feature_df =            date ticker       close   return1       sma10      vol20\n",
      "0    2019-01-30   AAPL   39.319290  0.068335   37....290  338.982001   8.553405\n",
      "6183 2025-09-05   TSLA  350.839996  0.036363  342.055002   8.564378\n",
      "\n",
      "[6184 rows x 6 columns]\n",
      "cfg = Config(run_id='week6-base', lake_root=WindowsPath('C:/Users/TJs PC/OneDrive/Desktop/Finance Data OS/lake'), output_ver... 'MSFT', 'NVDA', 'TSLA'], grids={'fast': [10, 15, 20, 25, 30], 'slow': [50, 100, 150, 200], 'vol': [15.0, 20.0, 25.0]})\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_cost_application_sign\u001b[39;49;00m(feature_df, cfg):\u001b[90m\u001b[39;49;00m\n",
      "        sig = build_signals_v2(feature_df, cfg.sma_fast, cfg.sma_slow, cfg.vol_window, cfg.vol_threshold_pct)\u001b[90m\u001b[39;49;00m\n",
      "        sig = normalize_signals_columns(sig)\u001b[90m\u001b[39;49;00m\n",
      "        daily = run_backtest_with_costs(sig, cost_bps=cfg.costs_bps)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# cost reduces returns or equal (when no trades)\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m (daily[\u001b[33m\"\u001b[39;49;00m\u001b[33mret_after_cost\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] <= daily[\u001b[33m\"\u001b[39;49;00m\u001b[33mreturn1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] + \u001b[94m1e-12\u001b[39;49;00m).all()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where False = all()\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where all = 0       0.000000\\n1       0.000000\\n2       0.000000\\n3       0.000000\\n4       0.000000\\n          ...   \\n6179   -0.035002\\n6180   -0.013508\\n6181    0.014361\\n6182    0.013290\\n6183    0.036363\\nName: ret_after_cost, Length: 6184, dtype: float64 <= (0       0.068335\\n1       0.007202\\n2       0.000480\\n3       0.028405\\n4       0.017110\\n          ...   \\n6179   -0.035002\\n6180   -0.013508\\n6181    0.014361\\n6182    0.013290\\n6183    0.036363\\nName: return1, Length: 6184, dtype: float64 + 1e-12).all\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31msrc\\tests\\test_units.py\u001b[0m:22: AssertionError\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "src/tests/test_units.py::test_cost_application_sign\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\fdos\\backtest.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "    d = d.groupby(\"ticker\", group_keys=False).apply(per_ticker)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[36m\u001b[1m============================================= short test summary info =============================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m src/tests/test_units.py::\u001b[1mtest_cost_application_sign\u001b[0m - assert False\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m4 deselected\u001b[0m, \u001b[33m2 warnings\u001b[0m\u001b[31m in 0.16s\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[33m\u001b[1m5 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.NO_TESTS_COLLECTED: 5>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytest, sys\n",
    "from pathlib import Path\n",
    "\n",
    "repo = Path.cwd() if Path.cwd().name == \"notebooks\" else Path.cwd() / \"notebooks\"\n",
    "tests_dir = repo / \"src\" / \"tests\"\n",
    "src_dir   = repo / \"src\"\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# drawdown/rolling\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_drawdown_roll\"])\n",
    "\n",
    "# transaction-cost sign\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_cost_application_sign\"])\n",
    "\n",
    "# tiny end-to-end smoke (writes v3 marts + validates)\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_e2e_small\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "583c7030-6996-4998-baf8-05271f092a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mF\u001b[0m\u001b[31m                                                                                                            [100%]\u001b[0m\n",
      "==================================================== FAILURES =====================================================\n",
      "\u001b[31m\u001b[1m___________________________________________ test_cost_application_sign ____________________________________________\u001b[0m\n",
      "\n",
      "feature_df =            date ticker       close   return1       sma10      vol20\n",
      "0    2019-01-30   AAPL   39.319290  0.068335   37....290  338.982001   8.553405\n",
      "6183 2025-09-05   TSLA  350.839996  0.036363  342.055002   8.564378\n",
      "\n",
      "[6184 rows x 6 columns]\n",
      "cfg = Config(run_id='week6-base', lake_root=WindowsPath('C:/Users/TJs PC/OneDrive/Desktop/Finance Data OS/lake'), output_ver... 'MSFT', 'NVDA', 'TSLA'], grids={'fast': [10, 15, 20, 25, 30], 'slow': [50, 100, 150, 200], 'vol': [15.0, 20.0, 25.0]})\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_cost_application_sign\u001b[39;49;00m(feature_df, cfg):\u001b[90m\u001b[39;49;00m\n",
      "        sig = build_signals_v2(feature_df, cfg.sma_fast, cfg.sma_slow, cfg.vol_window, cfg.vol_threshold_pct)\u001b[90m\u001b[39;49;00m\n",
      "        sig = normalize_signals_columns(sig)\u001b[90m\u001b[39;49;00m\n",
      "        daily = run_backtest_with_costs(sig, cost_bps=cfg.costs_bps)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# cost reduces returns or equal (when no trades)\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       in_mkt = daily[\u001b[33m\"\u001b[39;49;00m\u001b[33mposition\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] == \u001b[94m1\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where False = all()\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where all = 0       0.000000\\n1       0.000000\\n2       0.000000\\n3       0.000000\\n4       0.000000\\n          ...   \\n6179   -0.035002\\n6180   -0.013508\\n6181    0.014361\\n6182    0.013290\\n6183    0.036363\\nName: ret_after_cost, Length: 6184, dtype: float64 <= (0       0.068335\\n1       0.007202\\n2       0.000480\\n3       0.028405\\n4       0.017110\\n          ...   \\n6179   -0.035002\\n6180   -0.013508\\n6181    0.014361\\n6182    0.013290\\n6183    0.036363\\nName: return1, Length: 6184, dtype: float64 + 1e-12).all\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31msrc\\tests\\test_units.py\u001b[0m:22: AssertionError\n",
      "\u001b[33m================================================ warnings summary =================================================\u001b[0m\n",
      "..\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\.venv\\Lib\\site-packages\\_pytest\\config\\__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; typeguard\n",
      "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
      "\n",
      "src/tests/test_units.py::test_cost_application_sign\n",
      "  C:\\Users\\TJs PC\\OneDrive\\Desktop\\Finance Data OS\\notebooks\\src\\fdos\\backtest.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "    d = d.groupby(\"ticker\", group_keys=False).apply(per_ticker)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[36m\u001b[1m============================================= short test summary info =============================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m src/tests/test_units.py::\u001b[1mtest_cost_application_sign\u001b[0m - assert False\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m4 deselected\u001b[0m, \u001b[33m2 warnings\u001b[0m\u001b[31m in 0.16s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.TESTS_FAILED: 1>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys, importlib, pytest\n",
    "\n",
    "# 1) Make sure weâ€™re importing your local src/\n",
    "repo = Path.cwd() if Path.cwd().name == \"notebooks\" else Path.cwd() / \"notebooks\"\n",
    "src_dir  = repo / \"src\"\n",
    "tests_dir = src_dir / \"tests\"\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# 2) (optional) reload trades/backtest after your edits\n",
    "import fdos.trades as t, fdos.backtest as bt\n",
    "importlib.reload(t); importlib.reload(bt)\n",
    "\n",
    "# 3) Run only the cost-application test\n",
    "pytest.main([\"-q\", str(tests_dir), \"-k\", \"test_cost_application_sign\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68004708-df59-4183-93c5-b32921a94601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
